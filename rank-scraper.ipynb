{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank Scraper\n",
    "\n",
    "Ce programme permet d'extraire les données d'un site web qui a publié un classement musical. Les données alimentent la base sqlite database.db dans le sous répertoire data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Gothic\n",
    "  - Kerrang! : https://www.kerrang.com/the-16-essential-goth-albums-you-need-to-know\n",
    "    - no rank\n",
    "- Indie Rock\n",
    "  - https://www.melophobemusic.com/post/top-100-greatest-indie-rock-albums-of-all-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/61/11/1812ef6cbd7433ad240f72161ce5f84c4c450cede4db080365d371d29117/pandas-2.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pandas-2.2.1-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy<2,>=1.23.2 (from pandas)\n",
      "  Obtaining dependency information for numpy<2,>=1.23.2 from https://files.pythonhosted.org/packages/3f/6b/5610004206cf7f8e7ad91c5a85a8c71b2f2f8051a0c0c4d5916b76d6cbb2/numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------------------------- ------------ 41.0/61.0 kB 653.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.0/61.0 kB 806.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ayel\\onedrive - cegid\\documents\\dev\\chart-radar\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayel\\onedrive - cegid\\documents\\dev\\chart-radar\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.1-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.6 MB 22.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.4/11.6 MB 25.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.8/11.6 MB 26.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.6/11.6 MB 30.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.8/11.6 MB 33.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.6 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 36.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 27.3 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.3/15.8 MB 47.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 48.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.7/15.8 MB 47.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 9.0/15.8 MB 48.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.4/15.8 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.8/15.8 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 505.5/505.5 kB ? eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 345.4/345.4 kB ? eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.1 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    \"efe220cb-4981-40c7-8a6b-bd89b3569a17\":  { \n",
    "        #10. Juju – Siouxsie and The Banshees\n",
    "        \"urls\" : [\n",
    "            \"https://faroutmagazine.co.uk/the-10-greatest-goth-albums-of-all-time/\"\n",
    "        ],\n",
    "        \"regex\" : r'(\\d+)[.,]\\s(.+?)\\s?[–-]\\s(.*?)(?:\\s\\(.*\\))?$',\n",
    "        \"soup\" : 'h3',\n",
    "        \"artist_first\" : False,\n",
    "        \"name\" : \"Far Out\",\n",
    "        \"title\" : \"The 10 greatest goth albums of all time\",\n",
    "        \"style\" : \"Gothic\",\n",
    "        \"year\" : \"\",\n",
    "        \"date\" : \"22/05/2023\",\n",
    "        \"language\" : \"en\"\n",
    "    },\n",
    "    \"b2065bc7-68e3-4c64-878f-3700735126dd\":  { \n",
    "        #13. Red Lorry Yellow Lorry – Talk About the Weather (1985, Red Rhino)\n",
    "        \"urls\" : [\n",
    "            \"https://www.brooklynvegan.com/classic-goths-13-greatest-albums/\"\n",
    "        ],\n",
    "        \"regex\" : r'(\\d+)[.,]\\s(.+?)\\s?[–-]\\s(.*?)(?:\\s\\(.*\\))?$',\n",
    "        \"soup\" : 'strong',\n",
    "        \"artist_first\" : True,\n",
    "        \"name\" : \"Brooklyn Vegan\",\n",
    "        \"title\" : \"Classic Goth's 13 Greatest Albums\",\n",
    "        \"style\" : \"Gothic\",\n",
    "        \"year\" : \"\",\n",
    "        \"date\" : \"30/10/2020\",\n",
    "        \"language\" : \"en\"\n",
    "    },\n",
    "    \"116cbcd5-8721-49cb-8d1b-3cb897d8f338\":  { \n",
    "        #1. Joy Division- Closer (Factory, 1980) \n",
    "        \"urls\" : [\n",
    "            \"https://post-punk.com/40-years-of-goth-essential-albums-from-the-genres-beginnings/\"\n",
    "        ],\n",
    "        \"regex\" : r'(\\d+)[.,]\\s(.+?)\\s?[–-]\\s(.*?)(?:\\s\\(.*\\))?$',\n",
    "        \"soup\" : 'strong',\n",
    "        \"artist_first\" : True,\n",
    "        \"name\" : \"Post-punk.com\",\n",
    "        \"title\" : \"40 Years of Goth: Essential Albums from the Subculture’s Beginnings\",\n",
    "        \"style\" : \"Gothic\",\n",
    "        \"year\" : \"\",\n",
    "        \"date\" : \"31/10/2017\",\n",
    "        \"language\" : \"en\"\n",
    "    },\n",
    "    \"23d66e91-6dd9-4e1f-97db-984526ccc449\":  { \n",
    "        #10. Franz Ferdinand de Franz Ferdinand (2004) \n",
    "        \"urls\" : [\n",
    "            \"https://www.gqmagazine.fr/article/meilleurs-albums-indie-rock\"\n",
    "        ],\n",
    "        \"regex\" : r'(\\d+)\\.\\s(.*?)\\s(?:de|des)\\s(.*?)\\s\\((\\d+)\\)',\n",
    "        \"soup\" : 'h2',\n",
    "        \"artist_first\" : False,\n",
    "        \"name\" : \"GQ Magazine\",\n",
    "        \"title\" : \"Les 10 meilleurs albums d'indie rock de tous les temps\",\n",
    "        \"style\" : \"Indie Rock\",\n",
    "        \"year\" : \"\",\n",
    "        \"date\" : \"02/10/2023\",\n",
    "        \"language\" : \"fr\"\n",
    "    },\n",
    "    \"598ec7bb-043e-4fa6-b1e4-8e654571c961\":  {  \n",
    "        \"urls\" : [\n",
    "            \"https://www.nme.com/photos/the-500-greatest-albums-of-all-time-100-1-1426116\"\n",
    "        ],\n",
    "        \"regex\" :  r\"^(\\d+)([^,'']+)[,']?\\s*(.*?)'?$\",\n",
    "        \"soup\" : 'h2',\n",
    "        \"artist_first\" : True,\n",
    "        \"name\" : \"NME\",\n",
    "        \"title\" : \"The 500 Greatest Albums Of All Time\",\n",
    "        \"style\" : \"\",\n",
    "        \"year\" : \"\",\n",
    "        \"date\" : \"25/10/2013\",\n",
    "        \"language\" : \"en\"\n",
    "    },\n",
    "    \"598ec7bb-043e-4fa6-b1e4-8e654571c961\":  {  \n",
    "        \"urls\" : [\n",
    "            \"https://www.nme.com/photos/the-500-greatest-albums-of-all-time-200-101-1426258\"\n",
    "        ],\n",
    "        \"regex\" :  r\"^(\\d+)([^,'']+)[,']?\\s*(.*?)'?$\",\n",
    "        \"soup\" : 'h2',\n",
    "        \"artist_first\" : True,\n",
    "        \"name\" : \"NME\",\n",
    "        \"title\" : \"The 500 Greatest Albums Of All Time\",\n",
    "        \"style\" : \"\",\n",
    "        \"year\" : \"\",\n",
    "        \"date\" : \"25/10/2013\",\n",
    "        \"language\" : \"en\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import html\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_title(string):\n",
    "    if string[0].isdigit():\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste d'URLs à traiter\n",
    "url_list = ['https://spectrumculture.com/2013/03/21/13-best-goth-albums-of-all-time/',\n",
    "'https://spectrumculture.com/2013/03/21/13-best-goth-albums-of-all-time/2', \n",
    "        'https://spectrumculture.com/2013/03/21/13-best-goth-albums-of-all-time/3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_url(url):\n",
    "    # Create a session\n",
    "    session = requests.Session()\n",
    "\n",
    "    # Change the user agent and add Referer header\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "        'Referer': 'http://www.google.com/'\n",
    "    }\n",
    "\n",
    "    response = session.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Erreur lors de la récupération de la page. Code d'erreur : {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Delay between requests\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(html, soup_string):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    bold_titles = soup.find_all(soup_string)\n",
    "    return bold_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_title(title, regex_string, artist_first):\n",
    "    title_string = title.get_text()\n",
    "    title_string = re.sub(r'^\\W+', '', title_string)  # Remove special characters and spaces from the left\n",
    "    title_string = html.unescape(title_string)  # Convert HTML entities to normal characters\n",
    "    print(title_string)\n",
    "    if is_title(title_string):\n",
    "        match = re.match(regex_string, title_string)\n",
    "        if match:\n",
    "            rank = match.group(1)\n",
    "            if (artist_first):\n",
    "                artist = match.group(2)\n",
    "                title = match.group(3)\n",
    "            else :\n",
    "                title = match.group(2)\n",
    "                artist = match.group(3)\n",
    "            return {'rank': rank, 'artist': artist, 'title': title}\n",
    "        else:\n",
    "            print(f\"Failed to extract data from title: {title_string}\")\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data_list, id):\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df['id_ranking'] = id\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spectrum(url_list, soup, string_regex, artist_first):\n",
    "    data = []\n",
    "    for url in url_list:\n",
    "        html = fetch_url(url)\n",
    "        if html:\n",
    "            bold_titles = parse_html(html, soup)\n",
    "            for title in bold_titles:\n",
    "                data_item = extract_data_from_title(title, string_regex, artist_first)\n",
    "                if data_item:\n",
    "                    data.append(data_item)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection to the SQLite database\n",
    "# Doesn't matter if the database doesn't yet exist\n",
    "def save_to_sqlite(df):\n",
    "    conn = sqlite3.connect('./data/database.db')\n",
    "    df.to_sql('album', conn, if_exists='append', index=False)\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ranking(name, description, url, style, year, date, language):\n",
    "    # Create a connection to the SQLite database\n",
    "    conn = sqlite3.connect('./data/database.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Check if ranking with same url already exists\n",
    "    cursor.execute(\"SELECT id FROM ranking WHERE url = ?\", (url,))\n",
    "    data = cursor.fetchone()\n",
    "    if data:\n",
    "        # ranking already exists\n",
    "        conn.close()\n",
    "        return -1\n",
    "    \n",
    "    # Generate a unique ID\n",
    "    guid = str(uuid.uuid4())\n",
    "    \n",
    "    # Define the insert query\n",
    "    query = \"\"\"\n",
    "    INSERT INTO ranking (id, name, description, url, style, year, date, language, created_date)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    # Define the record to insert\n",
    "    record = (guid, name, description, url, style, year, date, language, datetime.now())\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(query, record)\n",
    "\n",
    "    # Commit the transaction and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    return guid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_ranking(url) :\n",
    "    conn = sqlite3.connect('./data/database.db')\n",
    "    cursor = conn.cursor()\n",
    "    # Get the ranking ID \n",
    "    cursor.execute(\"SELECT id FROM ranking WHERE url = ?\", (url,))\n",
    "    data = cursor.fetchone()\n",
    "    if data:\n",
    "        ranking_id = data[0]\n",
    "        # Delete the ranking\n",
    "        cursor.execute(\"DELETE FROM ranking WHERE url = ?\", (url,))\n",
    "        # Delete the albums\n",
    "        cursor.execute(\"DELETE FROM albums WHERE id_ranking = ?\", (ranking_id,))\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ranking_spectrum_gothic():\n",
    "    data=extract_spectrum(url_list)\n",
    "    id = add_ranking('Spectrum Culture', 'The 13 Best Goth Albums of All Time', 'https://spectrumculture.com/2013/03/21/13-best-goth-albums-of-all-time/', 'Gothic','')\n",
    "    df = create_dataframe(data,id)\n",
    "    save_to_sqlite(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_url(url, balise_html) :\n",
    "    data = []  \n",
    "    html = fetch_url(url)\n",
    "    if html:\n",
    "        titles = parse_html(html, balise_html)\n",
    "        for title in titles:\n",
    "            data.append(title.get_text())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data = [re.sub(r'^\\W+', '', title) for title in data]\n",
    "    data = [html.unescape(title) for title in data]\n",
    "    #data = [title.replace(',', '') for title in data]\n",
    "    #data = [title.replace(\"‘\", ',') for title in data]    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data):\n",
    "    extracted_data = []\n",
    "    for title in data:\n",
    "        match = re.match(r'^(\\d+)(.*?)\\s?[,‘](.*?)\\'?$', title)\n",
    "        if match:\n",
    "            rank = match.group(1)\n",
    "            artist = match.group(2)\n",
    "            title = match.group(3)\n",
    "            extracted_data.append({'rank': rank, 'artist': artist, 'title': title})\n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programme principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur dans la récupération des données\n"
     ]
    }
   ],
   "source": [
    "# json_params = json.dumps(params)\n",
    "# keys = list(params.keys())\n",
    "# for key in keys[4:4]:    \n",
    "#     urls = params[key][\"urls\"]\n",
    "#     regex = params[key][\"regex\"]\n",
    "#     artist_first = params[key][\"artist_first\"]\n",
    "#     soup = params[key][\"soup\"]\n",
    "#     data = extract_spectrum(urls, soup, regex, artist_first)\n",
    "#     df = create_dataframe(data,'uuid')\n",
    "#     ret = add_ranking(key, params[key][\"name\"], params[key][\"title\"], urls[0], params[key][\"style\"], params[key][\"year\"],params[key][\"date\"],params[key][\"language\"])\n",
    "#     df['id_ranking'] = key\n",
    "#     save_to_sqlite(df)\n",
    "#     print(df)\n",
    "\n",
    "# 0. Supprimer le classement\n",
    "#delete_ranking('https://www.nme.com/photos/the-500-greatest-albums-of-all-time-100-1-1426116')\n",
    "# 1. Récupérer les informations brutes depuis le site web\n",
    "#data = extract_data_from_url(\"https://www.nme.com/photos/the-500-greatest-albums-of-all-time-100-1-1426116\", \"h2\")\n",
    "#data = extract_data_from_url(\"https://www.nme.com/photos/the-500-greatest-albums-of-all-time-200-101-1426258\", \"h2\")\n",
    "#data = extract_data_from_url(\"https://www.nme.com/photos/the-500-greatest-albums-of-all-time-300-201-1426482\", \"h2\")\n",
    "#data = extract_data_from_url(\"https://www.nme.com/photos/the-500-greatest-albums-of-all-time-400-301-1426436\", \"h2\")\n",
    "#data = extract_data_from_url(\"https://www.nme.com/photos/the-500-greatest-albums-of-all-time-500-401-1426363\", \"h2\")\n",
    "data = extract_data_from_url(\"https://www.gqmagazine.fr/article/meilleurs-albums-indie-rock\", \"h2\")\n",
    "# 2. Nettoyer les données\n",
    "data_clean = clean_data(data)\n",
    "# 3. Extraire les données de la liste (rank, artist, title)\n",
    "data_extract = extract_data(data_clean)\n",
    "#pprint.pprint(data_extract)\n",
    "# 4. Contrôle la position des données dans la liste\n",
    "if (len(data_extract) == 99) :\n",
    "    # 4. Créer le classement dans la base de données\n",
    "    #id = add_ranking('NME', 'The 500 Greatest Albums Of All Time', 'https://www.nme.com/photos/the-500-greatest-albums-of-all-time-100-1-1426116', '', '', '25/10/2013', 'en')\n",
    "    #df = create_dataframe(data_extract,id)\n",
    "    df = create_dataframe(data_extract,\"5cced476-cbcb-4829-a110-1bd03ec1fb0c\")\n",
    "    #df = create_dataframe(data_extract,id)\n",
    "    # Convert rank to integer\n",
    "    df['rank'] = df['rank'].astype(int)\n",
    "    # invert ranking and add 100\n",
    "    df['rank'] = 101 - df['rank'].astype(int)+400\n",
    "    save_to_sqlite(df)\n",
    "    print(df)\n",
    "else : \n",
    "    print(\"Erreur dans la récupération des données\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
